{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2020, -1.1114])\n",
      "tensor([0.4497, 0.2476])\n",
      "tensor([-0.7992, -1.3959])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:257: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "F:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:258: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "input = torch.autograd.variable(torch.randn(2))\n",
    "print(input)\n",
    "print(nn.Sigmoid()(input))\n",
    "print(nn.LogSigmoid()(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "def swish(x,beta=1):\n",
    "    return x * torch.nn.Sigmoid()(x*beta)\n",
    "def mish(x):\n",
    "    return x * (torch.tanh(F.softplus(x)))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x * (torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.5000, 6.0000],\n",
      "        [0.1000, 0.0000, 3.0000]])\n",
      "tensor([2, 1])\n",
      "Softmax: tensor([[0.0179, 0.0040, 0.9781],\n",
      "        [0.0498, 0.0451, 0.9051]])\n",
      "logsoftmax: tensor([[-4.0222, -5.5222, -0.0222],\n",
      "        [-2.9997, -3.0997, -0.0997]])\n",
      "NLLLoss: tensor(1.5609)\n",
      "CrossEntropyLoss: tensor(1.5609)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "logits = torch.autograd.Variable(torch.tensor([[2,  0.5,6], [0.1,0,  3]]))\n",
    "labels = torch.autograd.Variable(torch.LongTensor([2,1]))\n",
    "print(logits)\n",
    "print(labels)\n",
    "print('Softmax:',torch.nn.Softmax(dim=1)(logits))\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)(logits)\n",
    "print('logsoftmax:',logsoftmax)\n",
    "output = torch.nn.NLLLoss()(logsoftmax, labels)\n",
    "print('NLLLoss:',output)\n",
    "print ( 'CrossEntropyLoss:', torch.nn.CrossEntropyLoss()(logits, labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 退化学习率：在训练过程中能够把大学习率和小学习率的优点都发挥出来，在训练刚开始时，使用大的学习率加快速度，训练到一定程度后使用小的学习率来提高精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "titanic_data = pd.read_csv(\"titanic3.csv\")\n",
    "print(titanic_data.columns )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#用哑变量将指定字段转成one-hot\n",
    "titanic_data = pd.concat([titanic_data,\n",
    "                          pd.get_dummies(titanic_data['sex']),\n",
    "                          pd.get_dummies(titanic_data['embarked'],prefix=\"embark\"),\n",
    "                          pd.get_dummies(titanic_data['pclass'],prefix=\"class\")], axis=1)\n",
    "\n",
    "print(titanic_data.columns )\n",
    "print(titanic_data['sex'])\n",
    "print(titanic_data['female'])\n",
    "\n",
    "#处理None值\n",
    "titanic_data[\"age\"] = titanic_data[\"age\"].fillna(titanic_data[\"age\"].mean())\n",
    "titanic_data[\"fare\"] = titanic_data[\"fare\"].fillna(titanic_data[\"fare\"].mean())#乘客票价\n",
    "\n",
    "#删去无用的列\n",
    "titanic_data = titanic_data.drop(['name','ticket','cabin','boat','body','home.dest','sex','embarked','pclass'], axis=1)\n",
    "print(titanic_data.columns )\n",
    "#\n",
    "####################################\n",
    "\n",
    "\n",
    "#分离样本和标签\n",
    "labels = titanic_data[\"survived\"].to_numpy()\n",
    "\n",
    "titanic_data = titanic_data.drop(['survived'], axis=1)\n",
    "data = titanic_data.to_numpy()\n",
    "\n",
    "#样本的属性名称\n",
    "feature_names = list(titanic_data.columns)\n",
    "\n",
    "\n",
    "#将样本分为训练和测试两部分\n",
    "np.random.seed(10)#设置种子，保证每次运行所分的样本一致\n",
    "train_indices = np.random.choice(len(labels), int(0.7*len(labels)), replace=False)\n",
    "test_indices = list(set(range(len(labels))) - set(train_indices))\n",
    "train_features = data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "test_features = data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "len(test_labels)#393\n",
    "###########################################\n",
    "\n",
    "class Mish(nn.Module):#Mish激活函数\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Mish activation loaded...\")\n",
    "    def forward(self,x):\n",
    "        x = x * (torch.tanh(F.softplus(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "torch.manual_seed(0)  #设置随机种子\n",
    "\n",
    "class ThreelinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(12, 12)\n",
    "        self.mish1 = Mish()\n",
    "        self.linear2 = nn.Linear(12, 8)\n",
    "        self.mish2 = Mish()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.criterion = nn.CrossEntropyLoss() #定义交叉熵函数\n",
    "\n",
    "    def forward(self, x): #定义一个全连接网络\n",
    "        lin1_out = self.linear1(x)\n",
    "        out1 = self.mish1(lin1_out)\n",
    "        out2 = self.mish2(self.linear2(out1))\n",
    "\n",
    "        return self.softmax(self.linear3(out2))\n",
    "    \n",
    "\n",
    "    def getloss(self,x,y): #实现LogicNet类的损失值计算接口\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.criterion(y_pred,y)#计算损失值得交叉熵\n",
    "        return loss\n",
    "\n",
    "##############################\n",
    "        \n",
    "net = ThreelinearModel()\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.04)\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor)\n",
    "label_tensor = torch.from_numpy(train_labels)\n",
    "\n",
    "losses = []#定义列表，用于接收每一步的损失值\n",
    "for epoch in range(num_epochs): \n",
    "    loss = net.getloss(input_tensor,label_tensor)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()#清空之前的梯度\n",
    "    loss.backward()#反向传播损失值\n",
    "    optimizer.step()#更新参数\n",
    "    if epoch % 20 == 0:\n",
    "        print ('Epoch {}/{} => Loss: {:.2f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "torch.save(net.state_dict(), 'models/titanic_model.pt')    \n",
    "\n",
    "from code_02_moons_fun import plot_losses\n",
    "plot_losses(losses)\n",
    "\n",
    "#输出训练结果\n",
    "out_probs = net(input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Train Accuracy:\", sum(out_classes == train_labels) / len(train_labels))\n",
    "\n",
    "#测试模型\n",
    "test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)\n",
    "out_probs = net(test_input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Test Accuracy:\", sum(out_classes == test_labels) / len(test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51a9663a131f1b5758c45b97a2d6917c8ae86b33e231c3733631cbc7265cfc89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
