# 图神经网络  
ps：本部分其实是一个很庞大的学习工程中的一部分而已，本博客截取了其中与图神经网络相关的部分。  
github项目链接地址：https://github.com/YunHao-Von/GNN_Learn   
## 1.图卷积神经网络概述  
### 1.1.1概述与拉普拉斯矩阵
实质：对节点之间的图结构关系进行计算，并且把计算结果作用在各个节点的属性特征的拟合当中。  
图卷积的操作与注意力机制的做法非常相似，是将输入的节点特征、权重参数、加工后的邻接矩阵三者放在一起执行点积运算。    
图卷积将未知的标签特征传播到已知标签的特征节点上，利用已知标签节点的分类器对未知标签特征的属性进行推理。  
步骤如下：  
(1)先将图结构的特征用拉普拉斯矩阵表示。    
(2)将拉普拉斯矩阵作用在节点特征得分计算模型中，完成节点特征的拟合。  
拉普拉斯矩阵的主要用途是论述图结构的特征，是图卷积操作的必要步骤。    
拉普拉斯矩阵的三种形式：  
(1)组合拉普拉斯矩阵：$L=D-A$，这种换算方式更关注图结构中相邻节点的差分。  
(2)对称归一化拉普拉斯矩阵：  
(3)随机归一化拉普拉斯矩阵。    
### 1.1.2谱图论  
谱图论研究如何通过几个容易计算的定量来描述图的性质。通常的方法是将图结构数据编码成一个矩阵，然后计算矩阵的特征值。  
这个特征值就称为图的谱。   
被编码后的矩阵就可以被理解为图的谱域。  
对矩阵的拉普拉斯变换，就是对图结构提取特征（谱）的一种方法。  
局部参数共享：算子是适用于每个顶点的，处处共享。  
感受域与层数成正比：最开始的时候，每个顶点直接包含了直接邻居的信息，在计算第二层的时候，就可以把邻居顶点的信息包含进来，这样参与运算的信息就会更多。层数越多，感受域越广，参与运算的信息也就越多。  
### 1.1.3图注意网络  
图注意网络在GCN的基础上添加了一个隐藏的自注意力层，通过叠加self-attention层，在卷积过程中可以将不同的重要性分配给了邻域内的不同顶点，同时处理不同大小的邻域。  
## 2.GCN缺陷  
